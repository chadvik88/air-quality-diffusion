{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd9a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your feature-engineered data\n",
    "df = pd.read_csv(\"../data/feature_engineered_data.csv\", index_col=0)\n",
    "\n",
    "# Drop non-numeric (just in case), and fill NA\n",
    "df = df.select_dtypes(include='number').fillna(method='ffill')\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(df)\n",
    "\n",
    "df_scaled = pd.DataFrame(scaled, columns=df.columns, index=df.index)\n",
    "\n",
    "# Save it\n",
    "df_scaled.to_csv(\"../data/scaled_data.csv\")\n",
    "print(\"scaled_data.csv created and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200cc5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load scaled data\n",
    "df_scaled = pd.read_csv(\"../data/feature_engineered_data.csv\", index_col=0)\n",
    "sequence_length = 30\n",
    "sequences = []\n",
    "\n",
    "# Slide window across the data\n",
    "for i in range(len(df_scaled) - sequence_length):\n",
    "    seq = df_scaled.iloc[i:i+sequence_length].values.flatten()\n",
    "    sequences.append(seq)\n",
    "\n",
    "df_seq = pd.DataFrame(sequences)\n",
    "\n",
    "# Save it\n",
    "df_seq.to_csv(\"../data/sequence_data.csv\")\n",
    "print(\"sequence_data.csv created and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dc6d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"You're using a device that's currently running on a:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67946e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load top features\n",
    "df = pd.read_csv('../data/top_features.csv', index_col=0)\n",
    "\n",
    "# Define target (you can choose another target if needed)\n",
    "target_column = df.columns[0]\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# Normalize features (Diffusion models benefit from scaled inputs)\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tensor, y_tensor, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: { X_train.shape }\")\n",
    "print(f\"Test set shape: { X_test.shape }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b924fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Simple denoiser MLP\n",
    "class DenoiseMLP(nn.Module):\n",
    "    def __init__(self, input_dim, time_embed_dim=64):\n",
    "        super(DenoiseMLP, self).__init__()\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, time_embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(time_embed_dim, input_dim)\n",
    "        )\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t_embed = self.time_mlp(t)\n",
    "        return self.model(x + t_embed)\n",
    "\n",
    "\n",
    "# Beta schedule (linear noise increase)\n",
    "def linear_beta_schedule(timesteps, beta_start=1e-4, beta_end=0.02):\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "# Hyperparameters\n",
    "timesteps = 1000\n",
    "betas = linear_beta_schedule(timesteps)\n",
    "alphas = 1. - betas\n",
    "alpha_hats = torch.cumprod(alphas, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f381783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load features (we'll use autoencoder features for best performance)\n",
    "df = pd.read_csv(\"../data/autoencoder_features.csv\", index_col=0)\n",
    "X = torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "# Dataloader\n",
    "batch_size = 128\n",
    "dataset = TensorDataset(X)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize model\n",
    "input_dim = X.shape[1]\n",
    "model = DenoiseMLP(input_dim)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821e04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_timesteps(n):\n",
    "    return torch.randint(0, timesteps, (n,)).long()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch in tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        x = batch[0].to(device)\n",
    "        t = sample_timesteps(x.shape[0]).to(device).unsqueeze(-1).float()\n",
    "\n",
    "        # Add noise\n",
    "        noise = torch.randn_like(x)\n",
    "        sqrt_alpha_hat = alpha_hats[t.long()].sqrt().to(device)\n",
    "        sqrt_one_minus_alpha_hat = (1 - alpha_hats[t.long()]).sqrt().to(device)\n",
    "        x_t = sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * noise\n",
    "\n",
    "        # Predict noise\n",
    "        noise_pred = model(x_t, t / timesteps)\n",
    "        loss = F.mse_loss(noise_pred, noise)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {epoch_loss / len(loader):.6f}\")\n",
    "print(\"Training complete!!! Model saved to 'models/diffusion_model.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532b9a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, seq_length, n_features):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.n_features = n_features\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(seq_length * n_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, seq_length * n_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1)\n",
    "        out = self.net(x)\n",
    "        return out.view(batch_size, self.seq_length, self.n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fe0afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "import torch\n",
    "from diffusion_model import Simple1DDiffusionModel\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Set sequence parameters (same as training)\n",
    "sequence_length = 30\n",
    "df_seq = pd.read_csv(\"../data/feature_engineered_data.csv\", index_col=0)\n",
    "n_features = df_seq.shape[1]\n",
    "\n",
    "# Load model\n",
    "model = Simple1DDiffusionModel(seq_len=sequence_length)\n",
    "model.load_state_dict(torch.load(\"../models/pm25_diffusion_model.pth\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce16bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the scaled data\n",
    "df_scaled = pd.read_csv(\"../data/scaled_data.csv\", index_col=0)\n",
    "\n",
    "# Set the sequence length (should be 30 as used in training)\n",
    "sequence_length = 30\n",
    "\n",
    "# Create overlapping sequences\n",
    "sequences = []\n",
    "for i in range(len(df_scaled) - sequence_length):\n",
    "    seq = df_scaled.iloc[i:i+sequence_length].values.flatten()\n",
    "    sequences.append(seq)\n",
    "\n",
    "# Create DataFrame of sequences\n",
    "df_seq = pd.DataFrame(sequences)\n",
    "df_seq.to_csv(\"../data/sequence_data.csv\", index=False)\n",
    "\n",
    "print(\"sequence_data.csv regenerated and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from diffusion_model import Simple1DDiffusionModel\n",
    "\n",
    "# Ensure the working directory is set correctly\n",
    "\n",
    "print(\"Running DDPM Evaluation\")\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "print(\"Files in '../data':\", os.listdir(\"../data\"))\n",
    "\n",
    "# Load the scaled data\n",
    "df_scaled = pd.read_csv(\"../data/scaled_data.csv\", index_col=0)\n",
    "data = df_scaled.values\n",
    "n_features = data.shape[1]\n",
    "\n",
    "# Create model with proper seq_len\n",
    "model = Simple1DDiffusionModel(seq_len=30)\n",
    "model.load_state_dict(torch.load(\"../models/pm25_diffusion_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Sampling function (flattened input/output)\n",
    "@torch.no_grad()\n",
    "def sample_forecast(model, steps, input_dim, alpha=0.1):\n",
    "    x = torch.randn(1, input_dim)  # Start from noise\n",
    "    for t in reversed(range(steps)):\n",
    "        noise = model(x)\n",
    "        x = x - alpha * noise  # Smaller, smoother update instead of x = x - noise / steps\n",
    "    return x.squeeze().cpu().numpy()\n",
    "\n",
    "# Forecast\n",
    "forecast = sample_forecast(model, steps=100, input_dim=30, alpha=0.1)\n",
    "forecast = forecast.reshape(sequence_length, 1)\n",
    "\n",
    "true_seq = data[-sequence_length:]\n",
    "\n",
    "plt.plot(true_seq[:, 0], label=\"True (last seen)\", linewidth=2)\n",
    "plt.plot(forecast[:, 0], label=\"Forecast (DDPM)\", linewidth=2)\n",
    "# Ground truth\n",
    "true_seq = data[-sequence_length:]\n",
    "\n",
    "# Plot PM2.5\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(true_seq[:, 0], label=\"True (last seen)\", linewidth=2)\n",
    "plt.plot(forecast[:, 0], label=\"Forecast (DDPM)\", linewidth=2)\n",
    "plt.legend()\n",
    "plt.title(\"Forecasted PM2.5 vs True\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"PM2.5\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluation\n",
    "rmse = np.sqrt(mean_squared_error(true_seq[:, 0], forecast[:, 0]))\n",
    "r2 = r2_score(true_seq[:, 0], forecast[:, 0])\n",
    "\n",
    "print(\"DDPM Forecast Evaluation : \")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c06d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the same scaled data\n",
    "df_scaled = pd.read_csv(\"../data/scaled_data.csv\", index_col=0)\n",
    "data = df_scaled.values\n",
    "\n",
    "# Create sequences\n",
    "def create_sequences(data, seq_len=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_len):\n",
    "        X.append(data[i:i+seq_len])\n",
    "        y.append(data[i+seq_len][0])  # Predict PM2.5 only\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_all, y_all = create_sequences(data, seq_len=30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9153800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for each test point using last observed 30 steps\n",
    "ddpm_preds = []\n",
    "true_pm25 = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    last_sequence = X_test[i]  # shape: (30, n_features)\n",
    "    last_pm25_seq = last_sequence[:, 0]  # just PM2.5 input\n",
    "    \n",
    "    x = torch.tensor(last_pm25_seq, dtype=torch.float32).unsqueeze(0)  # (1, 30)\n",
    "    for t in reversed(range(100)):\n",
    "        noise = model(x)\n",
    "        x = x - 0.1 * noise\n",
    "    ddpm_preds.append(x.squeeze().detach().numpy()[0])\n",
    "    true_pm25.append(y_test[i])\n",
    "\n",
    "# Evaluate\n",
    "ddpm_preds = np.array(ddpm_preds)\n",
    "true_pm25 = np.array(true_pm25)\n",
    "rmse = np.sqrt(mean_squared_error(true_pm25, ddpm_preds))\n",
    "r2 = r2_score(true_pm25, ddpm_preds)\n",
    "\n",
    "print(\"DDPM Forecast Evaluation (Fixed)\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R²:   {r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
